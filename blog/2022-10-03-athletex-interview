---
title: Timeseries for fantasy sports prediction market
author: Pei-Shan Wu
author_title: QuestDB Team
author_url: https://github.com/pswu11
author_image_url: https://avatars.githubusercontent.com/pswu11
description:
  QuestDB 6.5 introduces a new `COPY` commands allowing importing large CSV
  files. This article reveals the story behind it and highlights the exciting
  benchmark results using this new SQL command.
keywords: [io_uring, benchmark, questdb, time series]
tags: [benchmark, engineering, release, performance, clickhouse]
image: /img/blog/2022-09-12/cover.png
---

import Screenshot from "@theme/Screenshot"

_Recently we started a brand-new series: developer stories, for which we interviewed different developers in our community for their actual experience building with QuestDB. For the first post of this series, we interviewed Kevin Kamto, Co-founder at AthleteX Markets._

<!--truncate-->

### 1. Hi Kevin, could you tell us more about yourself?

My name is Kevin, I'm one of the core contributors and co-founders of AthleteX. That means that on a day to day basis, I operate as head of sales, and a point of coordination for the team. 

### 2. How did you get to know time series databases in the first place? 

I've been working in the IoT space as a developer for many years. For a cool project I worked on, we needed to create a device that measured the WiFi usage in the company to observe the day to day patterns. That's when I got introduced to InfluxDB, one of the time series database pioneers at that time. 

### 3. Tell us more about AthleteX Markets, what is this project about?

This is the backstory: During the middle of COVID-19, there were a lot of markets seeing red. So we asked ourselves, what is an investor to do during this time? As someone who loves sports like soccer and basketball, I imagine that if I could put my money towards an athlete, I could keep it safe.

The idea of AthleteX is that you can invest in the performance of your favourite athletes. Essentially, 
we created a fantasy sports prediction market. You can go to the platform to either long or short the performance of an athlete by trading the Athlete Performance Tokens (APTs). The price of an APT is based on an athlete's in-game statistics. Taking baseball as an example, we determine price using the Wins Above Replacement (WAR) formula, and the price is updated in real-time. 

[option 1: the dashboard reflecting real-time athlete performance and the prices associated]

<Screenshot
  alt="Bar chart showing import comparison. From fast to slow: ClickHouse, QuestDB, Apache Pinot, TimescaleDB, DuckDB, and Apache Druid."
  title="Ingesting a 76GB CSV file, from fast to slow: ClickHouse, QuestDB, Apache Pinot, TimescaleDB, DuckDB, and Apache Druid."
  height={360}
  src="/img/blog/2022-09-12/cover.png"
  width={650}
/>

[option 2: the real-time pricing chart of longing Carlos Correa, a MLB athlete.]

<Screenshot
  alt="Bar chart showing import comparison. From fast to slow: ClickHouse, QuestDB, Apache Pinot, TimescaleDB, DuckDB, and Apache Druid."
  title="Ingesting a 76GB CSV file, from fast to slow: ClickHouse, QuestDB, Apache Pinot, TimescaleDB, DuckDB, and Apache Druid."
  height={360}
  src="/img/blog/2022-09-12/cover.png"
  width={650}
/>

### 4. How is the use case related to time series databases? 

Using MLB (baseball) as an example, some in-game metrics such as bats and home runs are generated every minute or every five minute. We must store all that information over time. Coming from an IoT background, the problem is not new to me. So instead of going with something like MySQL or MongoDB, which didn't make a lot of sense, I knew that a time series database was what we needed. 

### 5. Among all the available time series databases, why QuestDB? 

QuestDB is faster than its competitors and goes above and beyond what we need it to handle at the current stage. It's also convenient to use SQL as the query language. At the moment, we store thousands of time series every minute and both the ingestion and querying performance has been satisfying. At scale, we anticipate hundreds of millions of data points and expect QuestDB to handle it smoothly.  

### 6. Could you tell us more about the technical side of your use case and how QuestDB fits in? 
	
QuestDB is the core foundation of our entire backend infrastructure. Due to the feed-type nature of our application and the need to look up athlete 
stats very fast, we need a database to manage large time series data sets and provide fast queries time. 

Our data providers have all the sports related data for each season, sport, and player. And we have some Python scripts to grab all the data periodically, calculate the book value based on the WAR formula, and store it in QuestDB. QuestDB is the base layer that allows us to handle this kind of throughput. At the moment, we're storing nearly 2 millions records in QuestDB.

Further down in the data pipeline, we built an API using Kotlin to query QuestDB and show the charts on our frontend. And from this point on, it's more about the DeFi protocol than QuestDB, you can read our lite paper to get a deeper understanding on how our system was designed. 

### 7. What are the most common queries you use for your application?

We often use simple `SELECT` statements together with `WITH` and `ORDER BY`. We also dabbled with `SAMPLE BY` and the performance has been exemplary. 

### 8. Were there any challenges you ran into with QuestDB? And how did you overcome it?

We wanted to allow some users to query QuestDB directly using the web console or some dashboards, without having access to drop or alter any tables. It was not possible to do that directly since it's lacking a security layer or built-in authentication. We ended up writing our own API for this purpose.

> Notes from QuestDB team: Since QuestDB 6.3, we implemented a new 
> configuration `pg.security.readonly` to toggle the read-only mode for PGWire.  

### 9. What are some of the new features or functionalities you really look forward to in QuestDB? And why?

High availability is one thing we look forward to seeing in QuestDB. For now we try to scale the resources with the single instance but it come at the expense of some downtime. Replication is an important feature to ensure that the data is echoed correctly across all the replicas. 

We could also benefit a lot if QuestDB can work smoothly with Metabase or something similar to that. We've tried to create dashboards with Grafana but it doesn't appear to be as human friendly as Metabase, especially for the non-technical end users that we have. 

### 10. Anything more you'd like to tell the readers? 

AtheleteX 1.0.0 has just been released on Sept 10. If you're interested learning more about the project, check out our release announcement! 
